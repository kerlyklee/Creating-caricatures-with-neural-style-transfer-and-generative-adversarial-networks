{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "args\n",
      "WARNING:tensorflow:From C:\\Users\\Admin\\Anaconda3\\envs\\please\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.1/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "58892288/58889256 [==============================] - 133s 2us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "__main__:227: DeprecationWarning: `imsave` is deprecated!\n",
      "`imsave` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``imageio.imwrite`` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 0\n",
      "Loss: 35029578000.0\n",
      "Iteration 0 took 512.2847182750702 seconds\n",
      "Saved image to: None-1.png\n",
      "Iteration: 1\n",
      "Loss: 26014265000.0\n",
      "Iteration 1 took 513.295907497406 seconds\n",
      "Saved image to: None-2.png\n",
      "Iteration: 2\n",
      "Loss: 24448584000.0\n",
      "Iteration 2 took 511.9123709201813 seconds\n",
      "Saved image to: None-3.png\n",
      "Iteration: 3\n",
      "Loss: 24202609000.0\n",
      "Iteration 3 took 487.60249853134155 seconds\n",
      "Saved image to: None-4.png\n",
      "Iteration: 4\n",
      "Loss: 24215423000.0\n",
      "Iteration 4 took 488.27574825286865 seconds\n",
      "Saved image to: None-5.png\n",
      "Iteration: 5\n",
      "Loss: 24634210000.0\n",
      "Iteration 5 took 483.5387291908264 seconds\n",
      "Saved image to: None-6.png\n",
      "Iteration: 6\n",
      "Loss: 25295454000.0\n",
      "Iteration 6 took 485.641560792923 seconds\n",
      "Saved image to: None-7.png\n",
      "Iteration: 7\n",
      "Loss: 26248974000.0\n",
      "Iteration 7 took 486.5600895881653 seconds\n",
      "Saved image to: None-8.png\n",
      "Iteration: 8\n",
      "Loss: 26368332000.0\n",
      "Iteration 8 took 480.5464949607849 seconds\n",
      "Saved image to: None-9.png\n",
      "Iteration: 9\n",
      "Loss: 26642817000.0\n",
      "Iteration 9 took 476.7850730419159 seconds\n",
      "Saved image to: None-10.png\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "style-transfer.py - An implementation of the style transfer algorithm. It's a synthesis of the original paper, combined\n",
    "                    with the adaption to the loss function that adds in the variation loss factor for normalization.\n",
    "                    Components have been synthesized together.\n",
    "\n",
    "For reference:\n",
    "    - https://arxiv.org/pdf/1508.06576.pdf (original style loss paper)\n",
    "    - https://arxiv.org/pdf/1412.0035.pdf (explains the ideas behind variation loss)\n",
    "    - https://github.com/keras-team/keras/blob/master/examples/neural_style_transfer.py\n",
    "      (style transfer as given by the keras team)\n",
    "    - https://harishnarayanan.org/writing/artistic-style-transfer/ (longer tutorial that walks through convolutions)\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "import keras.backend as K\n",
    "from keras.applications import VGG16\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "from scipy.optimize import fmin_l_bfgs_b\n",
    "from scipy.misc import imsave\n",
    "\n",
    "import argparse\n",
    "import sys; sys.argv=['']; del sys\n",
    "\n",
    "parser = argparse.ArgumentParser(description='Image neural style transfer implemented with Keras')\n",
    "parser.add_argument('--content_img', default='C:/Users/Admin/Thesis/NeuralStyleTransfer/KatsePildid/city.png', type=str, help='Path to target content image')\n",
    "parser.add_argument('--style_img', default='C:/Users/Admin/Thesis/NeuralStyleTransfer/KatsePildid/style1.png', type=str, help='Path to target style image')\n",
    "parser.add_argument('--result_img_prefix', metavar='tulemus', type=str, help='Name of generated image')\n",
    "parser.add_argument('--iter', type=int, default=10, required=False, help='Number of iterations to run')\n",
    "parser.add_argument('--content_weight', type=float, default=0.025, required=False, help='Content weight')\n",
    "parser.add_argument('--style_weight', type=float, default=1.0, required=False, help='Style weight')\n",
    "parser.add_argument('--var_weight', type=float, default=1.0, required=False, help='Total Variation weight')\n",
    "parser.add_argument('--height', type=int, default=512, required=False, help='Height of the images')\n",
    "parser.add_argument('--width', type=int, default=512, required=False, help='Width of the images')\n",
    "\n",
    "args = parser.parse_args()\n",
    "print('args')\n",
    "\n",
    "# Params #\n",
    "\n",
    "img_height = args.height\n",
    "img_width = args.width\n",
    "img_size = img_height * img_width\n",
    "img_channels = 3\n",
    "\n",
    "content_path = args.content_img\n",
    "style_path = args.style_img\n",
    "target_path = args.result_img_prefix\n",
    "target_extension = '.png'\n",
    "\n",
    "CONTENT_IMAGE_POS = 0\n",
    "STYLE_IMAGE_POS = 1\n",
    "GENERATED_IMAGE_POS = 2\n",
    "\n",
    "# Params #\n",
    "\n",
    "\n",
    "def process_img(path):\n",
    "    \"\"\"\n",
    "    Function for processing images to the format we need\n",
    "    :param path: The path to the image\n",
    "    :return: The image as a data array, scaled and reflected\n",
    "    \"\"\"\n",
    "    # Open image and resize it\n",
    "    img = Image.open(path)\n",
    "    img = img.resize((img_width, img_height))\n",
    "\n",
    "    # Convert image to data array\n",
    "    data = np.asarray(img, dtype='float32')\n",
    "    data = np.expand_dims(data, axis=0)\n",
    "    data = data[:, :, :, :3]\n",
    "\n",
    "    # Apply pre-process to match VGG16 we are using\n",
    "    data[:, :, :, 0] -= 103.939\n",
    "    data[:, :, :, 1] -= 116.779\n",
    "    data[:, :, :, 2] -= 123.68\n",
    "\n",
    "    # Flip from RGB to BGR\n",
    "    data = data[:, :, :, ::-1]\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "def get_layers(content_matrix, style_matrix, generated_matrix):\n",
    "    \"\"\"\n",
    "    Returns the content and style layers we need for the transfer\n",
    "    :param content_matrix: The feature matrix of the content image\n",
    "    :param style_matrix:  The feature matrix of the style image\n",
    "    :param generated_matrix:  The feature matrix of the generated image\n",
    "    :return: A tuple of content layers and style layers\n",
    "    \"\"\"\n",
    "    # Prep the model for our new input sizes\n",
    "    input_tensor = K.concatenate([content_matrix, style_matrix, generated_matrix], axis=0)\n",
    "    model = VGG16(input_tensor=input_tensor, weights='imagenet', include_top=False)\n",
    "\n",
    "    # Convert layers to dictionary\n",
    "    layers = dict([(layer.name, layer.output) for layer in model.layers])\n",
    "\n",
    "    # Pull the specific layers we want\n",
    "    c_layers = layers['block2_conv2']\n",
    "    s_layers = ['block1_conv2', 'block2_conv2', 'block3_conv3', 'block4_conv3', 'block5_conv3']\n",
    "    s_layers = [layers[layer] for layer in s_layers]\n",
    "\n",
    "    return c_layers, s_layers\n",
    "\n",
    "\n",
    "def content_loss(content_features, generated_features):\n",
    "    \"\"\"\n",
    "    Computes the content loss\n",
    "    :param content_features: The features of the content image\n",
    "    :param generated_features: The features of the generated image\n",
    "    :return: The content loss\n",
    "    \"\"\"\n",
    "    return 0.5 * K.sum(K.square(generated_features - content_features))\n",
    "\n",
    "\n",
    "def gram_matrix(features):\n",
    "    \"\"\"\n",
    "    Calculates the gram matrix of the feature representation matrix\n",
    "    :param features: The feature matrix that is used to calculate the gram matrix\n",
    "    :return: The gram matrix\n",
    "    \"\"\"\n",
    "    return K.dot(features, K.transpose(features))\n",
    "\n",
    "\n",
    "def style_loss(style_matrix, generated_matrix):\n",
    "    \"\"\"\n",
    "    Computes the style loss of the transfer\n",
    "    :param style_matrix: The style representation from the target style image\n",
    "    :param generated_matrix: The style representation from the generated image\n",
    "    :return: The loss from the style content\n",
    "    \"\"\"\n",
    "    # Permute the matrix to calculate proper covariance\n",
    "    style_features = K.batch_flatten(K.permute_dimensions(style_matrix, (2, 0, 1)))\n",
    "    generated_features = K.batch_flatten(K.permute_dimensions(generated_matrix, (2, 0, 1)))\n",
    "\n",
    "    # Get the gram matrices\n",
    "    style_mat = gram_matrix(style_features)\n",
    "    generated_mat = gram_matrix(generated_features)\n",
    "\n",
    "    return K.sum(K.square(style_mat - generated_mat)) / (4.0 * (img_channels ** 2) * (img_size ** 2))\n",
    "\n",
    "\n",
    "def variation_loss(generated_matrix):\n",
    "    \"\"\"\n",
    "    Computes the variation loss metric (used for normalization)\n",
    "    :param generated_matrix: The generated matrix\n",
    "    :return: The variation loss term for normalization\n",
    "    \"\"\"\n",
    "    a = K.square(generated_matrix[:, :img_height-1, :img_width-1, :] - generated_matrix[:, 1:, :img_width-1, :])\n",
    "    b = K.square(generated_matrix[:, :img_height-1, :img_width-1, :] - generated_matrix[:, :img_height-1, 1:, :])\n",
    "\n",
    "    return K.sum(K.pow(a + b, 1.25))\n",
    "\n",
    "\n",
    "def total_loss(c_layer, s_layers, generated):\n",
    "    \"\"\"\n",
    "    Computes the total loss of a given iteration\n",
    "    :param c_layer: The layer used to compute the content loss\n",
    "    :param s_layers: The layer(s) used to compute the style loss\n",
    "    :param generated: The generated image\n",
    "    :return: The total loss\n",
    "    \"\"\"\n",
    "\n",
    "    content_weight = args.content_weight\n",
    "    style_weight = args.style_weight\n",
    "    variation_weight = args.var_weight\n",
    "\n",
    "    # Content loss\n",
    "    content_features = c_layer[CONTENT_IMAGE_POS, :, :, :]\n",
    "    generated_features = c_layer[GENERATED_IMAGE_POS, :, :, :]\n",
    "    c_loss = content_loss(content_features, generated_features)\n",
    "\n",
    "    # Style loss\n",
    "    s_loss = None\n",
    "    for layer in s_layers:\n",
    "        style_features = layer[STYLE_IMAGE_POS, :, :, :]\n",
    "        generated_features = layer[GENERATED_IMAGE_POS, :, :, :]\n",
    "        if s_loss is None:\n",
    "            s_loss = style_loss(style_features, generated_features) * (style_weight / len(s_layers))\n",
    "        else:\n",
    "            s_loss += style_loss(style_features, generated_features) * (style_weight / len(s_layers))\n",
    "\n",
    "    # Variation loss (for regularization)\n",
    "    v_loss = variation_loss(generated)\n",
    "\n",
    "    return content_weight * c_loss + s_loss + variation_weight * v_loss\n",
    "\n",
    "\n",
    "def eval_loss_and_grads(generated):\n",
    "    \"\"\"\n",
    "    Computes the loss and gradients\n",
    "    :param generated: The generated image\n",
    "    :return: The loss and the gradients\n",
    "    \"\"\"\n",
    "    generated = generated.reshape((1, img_height, img_width, 3))\n",
    "    outs = f_outputs([generated])\n",
    "    loss_value = outs[0]\n",
    "    grad_values = outs[1].flatten().astype('float64')\n",
    "    return loss_value, grad_values\n",
    "\n",
    "\n",
    "def save_image(filename, generated):\n",
    "    \"\"\"\n",
    "    Saves the generated image\n",
    "    :param filename: The filename that the image is saved to\n",
    "    :param generated: The image that we want saved\n",
    "    :return: Nothing\n",
    "    \"\"\"\n",
    "    # Reshape image and flip from BGR to RGB\n",
    "    generated = generated.reshape((img_height, img_width, 3))\n",
    "    generated = generated[:, :, ::-1]\n",
    "\n",
    "    # Re-apply the mean shift\n",
    "    generated[:, :, 0] += 103.939\n",
    "    generated[:, :, 1] += 116.779\n",
    "    generated[:, :, 2] += 123.68\n",
    "\n",
    "    # Clip values to 0-255\n",
    "    generated = np.clip(generated, 0, 255).astype('uint8')\n",
    "\n",
    "    imsave(filename, Image.fromarray(generated))\n",
    "\n",
    "\n",
    "class Evaluator(object):\n",
    "    \"\"\"\n",
    "    Evaluator class used to track gradients and loss values together\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.loss_value = None\n",
    "        self.grad_values = None\n",
    "\n",
    "    def loss(self, x):\n",
    "        assert self.loss_value is None\n",
    "        loss_value, grad_values = eval_loss_and_grads(x)\n",
    "        self.loss_value = loss_value\n",
    "        self.grad_values = grad_values\n",
    "        return self.loss_value\n",
    "\n",
    "    def grads(self, x):\n",
    "        assert self.loss_value is not None\n",
    "        grad_values = np.copy(self.grad_values)\n",
    "        self.loss_value = None\n",
    "        self.grad_values = None\n",
    "        return grad_values\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # Prepare the generated image\n",
    "    generated_img = np.random.uniform(0, 255, (1, img_height, img_width, 3)) - 128.\n",
    "\n",
    "    # Load the respective content and style images\n",
    "    content = process_img(content_path)\n",
    "    style = process_img(style_path)\n",
    "\n",
    "    # Prepare the variables for the flow graph\n",
    "    content_image = K.variable(content)\n",
    "    style_image = K.variable(style)\n",
    "    generated_image = K.placeholder((1, img_height, img_width, 3))\n",
    "    loss = K.variable(0.)\n",
    "\n",
    "    # Grab the layers needed to prepare the loss metric\n",
    "    content_layer, style_layers = get_layers(content_image, style_image, generated_image)\n",
    "\n",
    "    # Define loss and gradient\n",
    "    loss = total_loss(content_layer, style_layers, generated_image)\n",
    "    grads = K.gradients(loss, generated_image)\n",
    "\n",
    "    # Define the output\n",
    "    outputs = [loss]\n",
    "    outputs += grads\n",
    "    f_outputs = K.function([generated_image], outputs)\n",
    "\n",
    "    evaluator = Evaluator()\n",
    "    iterations = args.iter\n",
    "\n",
    "    name = '{}-{}{}'.format(target_path, 0, target_extension)\n",
    "    save_image(name, generated_img)\n",
    "\n",
    "    for i in range(iterations):\n",
    "        print('Iteration:', i)\n",
    "        start_time = time.time()\n",
    "        generated_img, min_val, info = fmin_l_bfgs_b(evaluator.loss, generated_img.flatten(),\n",
    "                                                     fprime=evaluator.grads, maxfun=20)\n",
    "        print('Loss:', min_val)\n",
    "        end_time = time.time()\n",
    "        print('Iteration {} took {} seconds'.format(i, end_time - start_time))\n",
    "        name = '{}-{}{}'.format(target_path, i+1, target_extension)\n",
    "        save_image(name, generated_img)\n",
    "        print('Saved image to: {}'.format(name))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
