{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Admin\\Anaconda3\\envs\\please\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From <ipython-input-1-e6c383905d44>:88: conv2d_transpose (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.conv2d_transpose instead.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Shapes must be equal rank, but are 4 and 3",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32m~\\Anaconda3\\envs\\please\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36mset_shape\u001b[1;34m(self, shape)\u001b[0m\n\u001b[0;32m    536\u001b[0m           \u001b[0mdim_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 537\u001b[1;33m           unknown_shape)\n\u001b[0m\u001b[0;32m    538\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mInvalidArgumentError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: Shapes must be equal rank, but are 4 and 3",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-e6c383905d44>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    363\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"__main__\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    364\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 365\u001b[1;33m     \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    366\u001b[0m     \u001b[1;31m# test()\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    367\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-1-e6c383905d44>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m()\u001b[0m\n\u001b[0;32m    273\u001b[0m         \u001b[0mis_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplaceholder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbool\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'is_train'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    274\u001b[0m     \u001b[0mfake_image\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgenerator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrandom_input\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_dim\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mis_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 275\u001b[1;33m     \u001b[0mneeded_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtensor_into_nparray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfake_image\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    276\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    277\u001b[0m     '''predict_fn = predictor.from_saved_model('C:/Users/Admin/Thesis/GAN_Caroly')\n",
      "\u001b[1;32m<ipython-input-1-e6c383905d44>\u001b[0m in \u001b[0;36mtensor_into_nparray\u001b[1;34m(fake_image)\u001b[0m\n\u001b[0;32m    233\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mtensor_into_nparray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfake_image\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    234\u001b[0m         \u001b[0mtype_int\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfake_image\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mint32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 235\u001b[1;33m         \u001b[0mgen_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtype_int\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_shape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m129\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m128\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    236\u001b[0m         \u001b[1;31m#gen_right = gen_size.reshape(129,128,3)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    237\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\please\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36mset_shape\u001b[1;34m(self, shape)\u001b[0m\n\u001b[0;32m    538\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mInvalidArgumentError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    539\u001b[0m       \u001b[1;31m# Convert to ValueError for backwards compatibility.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 540\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    541\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    542\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Shapes must be equal rank, but are 4 and 3"
     ]
    }
   ],
   "source": [
    "\n",
    "# generate caricatures\n",
    "# code inspierd from https://github.com/llSourcell/Pokemon_GAN\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import cv2\n",
    "import random\n",
    "import scipy.misc\n",
    "from utils import *\n",
    "from keras.preprocessing.image import img_to_array\n",
    "from keras.models import load_model\n",
    "import argparse\n",
    "import imutils\n",
    "from scipy.misc import imresize\n",
    "import matplotlib.pyplot as plt\n",
    "import sys; sys.argv=['']; del sys\n",
    "from tensorflow.contrib import predictor\n",
    "import torch\n",
    "\n",
    "\n",
    "\n",
    "HEIGHT, WIDTH, CHANNEL = 128, 128, 3\n",
    "BATCH_SIZE = 64\n",
    "EPOCH = 5000\n",
    "version = 'new_caricatures9'\n",
    "newCaric_path = './' + version\n",
    "\n",
    "\n",
    "# lrelu function\n",
    "def lrelu(x, n, leak=0.2): \n",
    "    return tf.maximum(x, leak * x, name=n) \n",
    "# get rigth caricature data\n",
    "'''def process_data():   \n",
    "    current_dir = os.getcwd()\n",
    "    caricature_dir = os.path.join(current_dir, 'Caricature_Data')\n",
    "    images = []\n",
    "    for each in os.listdir(caricature_dir): \n",
    "        images.append(os.path.join(caricature_dir,each))\n",
    "    # print images    \n",
    "    all_images = tf.convert_to_tensor(images, dtype = tf.string)\n",
    "    \n",
    "    images_queue = tf.train.slice_input_producer([all_images])\n",
    "                                        \n",
    "    content = tf.read_file(images_queue[0])\n",
    "    image = tf.image.decode_image(content, channels = CHANNEL)\n",
    "    #change to get more difrent\n",
    "    image = tf.image.random_flip_left_right(image)\n",
    "    image = tf.image.random_brightness(image, max_delta = 0.1)\n",
    "    image = tf.image.random_contrast(image, lower = 0.9, upper = 1.1)\n",
    "\n",
    "    size = [HEIGHT, WIDTH]\n",
    "    image = tf.image.resize_images(image, size)\n",
    "    image.set_shape([HEIGHT,WIDTH,CHANNEL])\n",
    "\n",
    "    #change tensor type\n",
    "    image = tf.cast(image, tf.float32)\n",
    "    image = image / 255.0\n",
    "    \n",
    "    iamges_batch = tf.train.shuffle_batch(\n",
    "                                    [image], batch_size = BATCH_SIZE,\n",
    "                                    num_threads = 4, capacity = 200 + 3* BATCH_SIZE,\n",
    "                                    min_after_dequeue = 200)\n",
    "    num_images = len(images)\n",
    "\n",
    "    return iamges_batch, num_images '''\n",
    "\n",
    "def generator(input, random_dim, is_train, reuse=False):\n",
    "    c4, c8, c16, c32, c64 = 512, 256, 128, 64, 36 # channel num\n",
    "    s4 = 4\n",
    "    output_dim = CHANNEL  # RGB image\n",
    "    with tf.variable_scope('gens') as scope:\n",
    "        if reuse:\n",
    "            scope.reuse_variables()\n",
    "        w1 = tf.get_variable('w1', shape=[random_dim, s4 * s4 * c4], dtype=tf.float32,\n",
    "                             initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
    "        b1 = tf.get_variable('b1', shape=[c4 * s4 * s4], dtype=tf.float32,\n",
    "                             initializer=tf.constant_initializer(0.0))\n",
    "        flat_conv1 = tf.add(tf.matmul(input, w1), b1, name='flat_conv1')\n",
    "         #Convolution, bias, activation, repeat! \n",
    "        conv1 = tf.reshape(flat_conv1, shape=[-1, s4, s4, c4], name='conv1')\n",
    "        bn1 = tf.contrib.layers.batch_norm(conv1, is_training=is_train, epsilon=1e-5, decay = 0.9,  updates_collections=None, scope='bn1')\n",
    "        act1 = tf.nn.relu(bn1, name='act1')\n",
    "        # 8*8*256\n",
    "        #Convolution, bias, activation, repeat! \n",
    "        conv2 = tf.layers.conv2d_transpose(act1, c8, kernel_size=[5, 5], strides=[2, 2], padding=\"SAME\",\n",
    "                                           kernel_initializer=tf.truncated_normal_initializer(stddev=0.02),\n",
    "                                           name='conv2')\n",
    "        bn2 = tf.contrib.layers.batch_norm(conv2, is_training=is_train, epsilon=1e-5, decay = 0.9,  updates_collections=None, scope='bn2')\n",
    "        act2 = tf.nn.relu(bn2, name='act2')\n",
    "        # 16*16*128\n",
    "        conv3 = tf.layers.conv2d_transpose(act2, c16, kernel_size=[5, 5], strides=[2, 2], padding=\"SAME\",\n",
    "                                           kernel_initializer=tf.truncated_normal_initializer(stddev=0.02),\n",
    "                                           name='conv3')\n",
    "        bn3 = tf.contrib.layers.batch_norm(conv3, is_training=is_train, epsilon=1e-5, decay = 0.9,  updates_collections=None, scope='bn3')\n",
    "        act3 = tf.nn.relu(bn3, name='act3')\n",
    "        # 32*32*64\n",
    "        conv4 = tf.layers.conv2d_transpose(act3, c32, kernel_size=[5, 5], strides=[2, 2], padding=\"SAME\",\n",
    "                                           kernel_initializer=tf.truncated_normal_initializer(stddev=0.02),\n",
    "                                           name='conv4')\n",
    "        bn4 = tf.contrib.layers.batch_norm(conv4, is_training=is_train, epsilon=1e-5, decay = 0.9,  updates_collections=None, scope='bn4')\n",
    "        act4 = tf.nn.relu(bn4, name='act4')\n",
    "        # 64*64*32\n",
    "        conv5 = tf.layers.conv2d_transpose(act4, c64, kernel_size=[5, 5], strides=[2, 2], padding=\"SAME\",\n",
    "                                           kernel_initializer=tf.truncated_normal_initializer(stddev=0.02),\n",
    "                                           name='conv5')\n",
    "        bn5 = tf.contrib.layers.batch_norm(conv5, is_training=is_train, epsilon=1e-5, decay = 0.9,  updates_collections=None, scope='bn5')\n",
    "        act5 = tf.nn.relu(bn5, name='act5')\n",
    "        \n",
    "        #128*128*3\n",
    "        conv6 = tf.layers.conv2d_transpose(act5, output_dim, kernel_size=[5, 5], strides=[2, 2], padding=\"SAME\",\n",
    "                                           kernel_initializer=tf.truncated_normal_initializer(stddev=0.02),\n",
    "                                           name='conv6')\n",
    "\n",
    "        # bn6 = tf.contrib.layers.batch_norm(conv6, is_training=is_train, epsilon=1e-5, decay = 0.9,  updates_collections=None, scope='bn6')\n",
    "        act6 = tf.nn.tanh(conv6, name='act6')\n",
    "        #your_session = tf.Session()\n",
    "        #array = (act6, is_train).eval(session=your_session)\n",
    "        #array = act6.numpy()\n",
    "        return act6\n",
    "\n",
    "\n",
    "#def discriminator(input, is_train, reuse=False):\n",
    "\n",
    "\n",
    "        #output = imutils.resize(orig, width=400)\n",
    "        #cv2.putText(output, label, (10, 25), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2)\n",
    "\n",
    "        #cv2.imshow('Image with predicted label', output)\n",
    "        #cv2.imwrite('../dataset/1.jpg', output)\n",
    "        #cv2.waitKey(0)\n",
    "    '''c2, c4, c8, c16 = 64, 128, 256, 512  # channel num: 64, 128, 256, 512\n",
    "    with tf.variable_scope('dis') as scope:\n",
    "        if reuse:\n",
    "            scope.reuse_variables()\n",
    "\n",
    "        #Convolution, activation, bias, repeat! \n",
    "        conv1 = tf.layers.conv2d(input, c2, kernel_size=[5, 5], strides=[2, 2], padding=\"SAME\",\n",
    "                                 kernel_initializer=tf.truncated_normal_initializer(stddev=0.02),\n",
    "                                 name='conv1')\n",
    "        bn1 = tf.contrib.layers.batch_norm(conv1, is_training = is_train, epsilon=1e-5, decay = 0.9,  updates_collections=None, scope = 'bn1')\n",
    "        act1 = lrelu(conv1, n='act1')\n",
    "         #Convolution, activation, bias, repeat! \n",
    "        conv2 = tf.layers.conv2d(act1, c4, kernel_size=[5, 5], strides=[2, 2], padding=\"SAME\",\n",
    "                                 kernel_initializer=tf.truncated_normal_initializer(stddev=0.02),\n",
    "                                 name='conv2')\n",
    "        bn2 = tf.contrib.layers.batch_norm(conv2, is_training=is_train, epsilon=1e-5, decay = 0.9,  updates_collections=None, scope='bn2')\n",
    "        act2 = lrelu(bn2, n='act2')\n",
    "        #Convolution, activation, bias, repeat! \n",
    "        conv3 = tf.layers.conv2d(act2, c8, kernel_size=[5, 5], strides=[2, 2], padding=\"SAME\",\n",
    "                                 kernel_initializer=tf.truncated_normal_initializer(stddev=0.02),\n",
    "                                 name='conv3')\n",
    "        bn3 = tf.contrib.layers.batch_norm(conv3, is_training=is_train, epsilon=1e-5, decay = 0.9,  updates_collections=None, scope='bn3')\n",
    "        act3 = lrelu(bn3, n='act3')\n",
    "         #Convolution, activation, bias, repeat! \n",
    "        conv4 = tf.layers.conv2d(act3, c16, kernel_size=[5, 5], strides=[2, 2], padding=\"SAME\",\n",
    "                                 kernel_initializer=tf.truncated_normal_initializer(stddev=0.02),\n",
    "                                 name='conv4')\n",
    "        bn4 = tf.contrib.layers.batch_norm(conv4, is_training=is_train, epsilon=1e-5, decay = 0.9,  updates_collections=None, scope='bn4')\n",
    "        act4 = lrelu(bn4, n='act4')\n",
    "       \n",
    "        # start from act4\n",
    "        dim = int(np.prod(act4.get_shape()[1:]))\n",
    "        fc1 = tf.reshape(act4, shape=[-1, dim], name='fc1')\n",
    "      \n",
    "        \n",
    "        w2 = tf.get_variable('w2', shape=[fc1.shape[-1], 1], dtype=tf.float32,\n",
    "                             initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
    "        b2 = tf.get_variable('b2', shape=[1], dtype=tf.float32,\n",
    "                             initializer=tf.constant_initializer(0.0))\n",
    "\n",
    " \n",
    "        logits = tf.add(tf.matmul(fc1, w2), b2, name='logits')\n",
    "        # dcgan\n",
    "        acted_out = tf.nn.sigmoid(logits)'''\n",
    "        #return logits #, acted_out\n",
    "\n",
    "\n",
    "def train():\n",
    "    #G(z)\n",
    "    random_dim = 100\n",
    "    loss_const = 3\n",
    "    def load_arguments():\n",
    "        parser = argparse.ArgumentParser()\n",
    "        parser.add_argument('-m', '--model', default='C:/Users/Admin/Thesis/GAN_Caroly', type=str, help='Path to model')\n",
    "\n",
    "        args = vars(parser.parse_args())\n",
    "\n",
    "\n",
    "        return args\n",
    "\n",
    "\n",
    "    def mk_square(img, desired_shp=1000):\n",
    "        x, y, _ = img.shape\n",
    "        maxs = max(img.shape[:2])\n",
    "        y2 = (maxs-y)//2\n",
    "        x2 = (maxs-x)//2\n",
    "        arr = np.zeros((maxs, maxs, 3), dtype=np.float32)\n",
    "        arr[int(np.floor(x2)):int(np.floor(x2)+x), int(np.floor(y2)):int(np.floor(y2)+y)] = img\n",
    "        return imresize(arr, (desired_shp , desired_shp))\n",
    "\n",
    "\n",
    "    def load_image(fake_image):\n",
    "        #image = cv2.imread(fake_image)\n",
    "        #image = img_to_array(fake_image)\n",
    "        image = mk_square(fake_image)\n",
    "        image = cv2.resize(image, (28, 28))\n",
    "        image = image.astype('float') / 255.0\n",
    "        plt.imshow(image)\n",
    "        image = np.expand_dims(image, axis=0)\n",
    "        return image\n",
    "\n",
    "\n",
    "\n",
    "    '''def load_original_image(args):\n",
    "        image = cv2.imread(args['image'])\n",
    "        return image.copy()'''\n",
    "\n",
    "\n",
    "    def load_trained_model(args):\n",
    "        print('[INFO] loading model...')\n",
    "        model = load_model(args['model'])\n",
    "        return model\n",
    "\n",
    "\n",
    "    def classify_image(model, image):\n",
    "        (caricature, portrait) = model.predict(image)[0]\n",
    "        probability = caricature if caricature > nonsenss else nonsenss\n",
    "        #print('Probability: ' + str(probability))\n",
    "        #label = '{}: {:.2f}%'.format(label, probability * 100)\n",
    "        return probability\n",
    "\n",
    "    def tensor_into_nparray(fake_image):\n",
    "        type_int = tf.cast(fake_image, dtype=tf.int32)\n",
    "        gen_size = type_int.set_shape((129,128,3))\n",
    "        #gen_right = gen_size.reshape(129,128,3)\n",
    "        \n",
    "        #print (gen_image)\n",
    "        #t = tf.cast(fake_image, dtype=tf.int32)\n",
    "        #t = tf.reshape(t, [-1])\n",
    "        #gen_image = tf.shape(tf.expand_dims(t, 1))\n",
    "        #print (gen_image)\n",
    "        #flattened = tf.reshape(t, shape=[tf.shape(t)[0].value, -1])\n",
    "        #print (flattened)\n",
    "        #tf.shape(t)[0]\n",
    "        #t = tf.shape(tf.s(fake_image))\n",
    "        gen_image = tf.cast(gen_right, dtype=tf.uint8)\n",
    "        \n",
    "        #your_session = tf.Session()\n",
    "        #array = tensor.eval(session=your_session)\n",
    "        jpeg_bin_tensor = tf.image.encode_jpeg(gen_image)\n",
    "\n",
    "        with tf.Session() as sess:\n",
    "            # display encoded back to image data\n",
    "            jpeg_bin = sess.run(jpeg_bin_tensor)\n",
    "            jpeg_str = StringIO.StringIO(jpeg_bin)\n",
    "            jpeg_image = PIL.Image.open(jpeg_str)\n",
    "            return jpeg_image\n",
    "    \n",
    "\n",
    "    '''def __main__():\n",
    "        args = load_arguments()\n",
    "        image = load_image(args)\n",
    "        model = load_trained_model(args)\n",
    "        label = classify_image(model, image)\n",
    "\n",
    "        orig = load_original_image(args)'''\n",
    "    \n",
    "    with tf.variable_scope('input'):\n",
    "        #real and fake image placholders\n",
    "        #real_image = tf.placeholder(tf.float32, shape = [None, HEIGHT, WIDTH, CHANNEL], name='real_image')\n",
    "        random_input = tf.placeholder(tf.float32, shape=[None, random_dim], name='rand_input')\n",
    "        is_train = tf.placeholder(tf.bool, name='is_train')\n",
    "    fake_image = generator(random_input, random_dim, is_train)\n",
    "    needed_data = tensor_into_nparray(fake_image)\n",
    "\n",
    "    '''predict_fn = predictor.from_saved_model('C:/Users/Admin/Thesis/GAN_Caroly')\n",
    "    predict_fn = a.encode('utf-8').strip()\n",
    "    predictions = predict_fn(fake_image)\n",
    "    print(predictions)'''\n",
    "    #size_fake_img = load_image(fake_image, is_train)\n",
    "    args = load_arguments()\n",
    "    model = load_trained_model(args)\n",
    "    loss = classify_image(model, needed_data)\n",
    "    d_loss = (1 - loss)*loss_const\n",
    "\n",
    "    #real_result = discriminator(real_image, is_train)\n",
    "\n",
    "    #fake_result = discriminator(fake_image, is_train, reuse=tf.AUTO_REUSE)\n",
    "    \n",
    "    #d_loss = tf.reduce_mean(fake_result) - tf.reduce_mean(loss*loss_const)  # This optimizes the dektective\n",
    "    g_loss = -tf.reduce_mean(d_loss) \n",
    "    t_vars = tf.trainable_variables()\n",
    "    #d_vars = [var for var in t_vars if 'dis' in var.name]\n",
    "    g_vars = [var for var in t_vars if 'gens' in var.name]\n",
    "    #trainer_d = tf.train.RMSPropOptimizer(learning_rate=2e-4).minimize(d_loss, var_list=d_vars)\n",
    "    trainer_g = tf.train.RMSPropOptimizer(learning_rate=2e-4).minimize(g_loss, var_list=g_vars)\n",
    "    # clip discriminator weights\n",
    "    #d_clip = [v.assign(tf.clip_by_value(v, -0.01, 0.01)) for v in d_vars]\n",
    "    batch_size = BATCH_SIZE\n",
    "    #image_batch, samples_num = process_data()   \n",
    "    #batch_num = int(samples_num / batch_size)\n",
    "    total_batch = 0\n",
    "\n",
    "            \n",
    "\n",
    "\n",
    "    sess = tf.Session()\n",
    "    saver = tf.train.Saver()\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    sess.run(tf.local_variables_initializer())\n",
    "    # continue training\n",
    "    save_path = saver.save(sess, \"/tmp/model.ckpt\")\n",
    "    ckpt = tf.train.latest_checkpoint('./model/' + version)\n",
    "    saver.restore(sess, save_path)\n",
    "    coord = tf.train.Coordinator()\n",
    "    threads = tf.train.start_queue_runners(sess=sess, coord=coord)\n",
    "\n",
    "    print('total training sample num:%d' % samples_num)\n",
    "    print('batch size: %d, batch num per epoch: %d, epoch num: %d' % (batch_size, batch_num, EPOCH))\n",
    "    print('start training...')\n",
    "    for i in range(EPOCH):\n",
    "        print(\"Running epoch {}/{}...\".format(i, EPOCH))\n",
    "        for j in range(batch_num):\n",
    "            print(j)\n",
    "            #d_iters = 5\n",
    "            g_iters = 1\n",
    "\n",
    "            train_noise = np.random.uniform(-1.0, 1.0, size=[batch_size, random_dim]).astype(np.float32)\n",
    "            '''for k in range(d_iters):\n",
    "                print(k)\n",
    "                train_image = sess.run(image_batch)\n",
    "                #clip weights\n",
    "                sess.run(d_clip)\n",
    "                \n",
    "                # Update the discriminator\n",
    "                _, dLoss = sess.run([trainer_d, d_loss],\n",
    "                                    feed_dict={random_input: train_noise, real_image: train_image, is_train: True})'''\n",
    "\n",
    "            # Update the generator\n",
    "            for k in range(g_iters):\n",
    "                _, gLoss = sess.run([trainer_g, g_loss],\n",
    "                                    feed_dict={random_input: train_noise, is_train: True})\n",
    "            \n",
    "        # save check point for model every 500 epoch\n",
    "        if i%500 == 0:\n",
    "            if not os.path.exists('./model/' + version):\n",
    "                os.makedirs('./model/' + version)\n",
    "            saver.save(sess, './model/' +version + '/' + str(i))  \n",
    "        if i%50 == 0:\n",
    "            # save image after every 50 epochs\n",
    "            if not os.path.exists(newCaric_path):\n",
    "                os.makedirs(newCaric_path)\n",
    "            sample_noise = np.random.uniform(-1.0, 1.0, size=[batch_size, random_dim]).astype(np.float32)\n",
    "            imgtest = sess.run(fake_image, feed_dict={random_input: sample_noise, is_train: False})\n",
    "            save_images(imgtest, [8,8] ,newCaric_path + '/epoch' + str(i) + '.jpg')\n",
    "            \n",
    "            print('train:[%d],g_loss:%f' % (i, gLoss))\n",
    "    coord.request_stop()\n",
    "    coord.join(threads)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    train()\n",
    "    # test()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
